# -*- coding: utf-8 -*-
"""Copy of Remote_Livestock_Management_Prediction_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rDA39qMhu49uV1CBpiyFs5qkgNe5c7-4

## **IMPORT LIBARIES**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns



"""# **LOAD AND PREVIEW DATASET**"""
df = pd.read_excel('cattle_dataset.xlsx')
print("Dataset Shape:", df.shape)
print("\nFirst few rows:")
print(df.head())
print("\nData Info:")
df.info()

"""# **Distribution of health status**"""

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='health_status', hue='health_status', palette={'healthy': 'green', 'unhealthy': 'red'}, legend=False)
plt.title('Distribution of Health Status')
plt.xlabel('Health Status')
plt.ylabel('Count')
plt.xticks(rotation=45)
#plt.show()

"""# **breed type distribution based on health status**"""

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='breed_type', hue='health_status', palette={'healthy': 'green', 'unhealthy': 'red'})
plt.title('Health Status by Breed Type')
plt.xlabel('Breed Type')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Health Status')
plt.tight_layout()
#plt.show()

"""# **Numerical features summary**"""

# Basic statistics for numerical columns
print("\nNumerical Features Statistics:")
print(df.describe())

numerical_cols = ['body_temperature', 'respiratory_rate', 'heart_rate', 'milk_production',
                  'sleeping_duration', 'eating_duration', 'walking_capacity',
                  'lying_down_duration', 'body_condition_score', 'rumen_fill', 'ruminating']

plt.figure(figsize=(18, 30))
for i, col in enumerate(numerical_cols):
    plt.subplot(len(numerical_cols) // 2 + 1, 2, i + 1)
    sns.boxplot(data=df, x='health_status', y=col)
    plt.title(f'{col.replace("_", " ").title()} vs Health Status')
    plt.xticks(rotation=30)

plt.tight_layout()
#plt.show()

df[numerical_cols].hist(figsize=(18, 12), bins=30, edgecolor='black')
plt.tight_layout()
#plt.show()

"""# **Categorical Features Summary**"""

# Summary for categorical features
print("\nCategorical Features Distribution:")

categorical_cols = ['breed_type', 'faecal_consistency', 'health_status']

for col in categorical_cols:
    print(f"\n{col} value counts:")
    print(df[col].value_counts())

categorical_cols = ['breed_type', 'faecal_consistency', 'health_status']

plt.figure(figsize=(18, 5))

for i, col in enumerate(categorical_cols):
    plt.subplot(1, 3, i + 1)
    sns.countplot(data=df, x=col, hue=col, legend=False)
    plt.title(f'{col.replace("_", " ").title()} Distribution')
    plt.xlabel(col.replace("_", " ").title())
    plt.ylabel('Count')
    plt.xticks(rotation=30)

plt.tight_layout()
#plt.show()
"""# Vital Sign Summary"""

# Vital sign features
vital_signs = ['body_temperature', 'respiratory_rate', 'heart_rate']

# Plot boxplots by health status with proper palette handling
plt.figure(figsize=(15, 5))

for i, col in enumerate(vital_signs, 1):
    plt.subplot(1, 3, i)
    sns.boxplot(data=df, x='health_status', y=col, hue='health_status', palette='coolwarm', legend=False)
    plt.title(f'{col.replace("_", " ").title()} by Health Status')
    plt.xlabel('Health Status')
    plt.ylabel(col.replace("_", " ").title())

plt.tight_layout()
#plt.show()

"""# Behavioural Analysis summary"""

# Behavioral features
behavioral_features = ['walking_capacity', 'sleeping_duration', 'eating_duration',
                       'lying_down_duration', 'ruminating', 'rumen_fill']

plt.figure(figsize=(18, 15))
for i, col in enumerate(behavioral_features):
    plt.subplot(3, 2, i + 1)
    sns.boxplot(data=df, x='health_status', y=col, hue='health_status', palette='Set2', legend=False)
    plt.title(f'{col.replace("_", " ").title()} vs Health Status')
    plt.xlabel('Health Status')
    plt.ylabel(col.replace("_", " ").title())

plt.tight_layout()
#plt.show()

# Define behavioral features
behavioral = ['walking_capacity', 'sleeping_duration', 'eating_duration',
              'lying_down_duration', 'ruminating', 'rumen_fill']

# Behavioral statistics grouped by health status
print("\nBehavioral Patterns Statistics:")
for col in behavioral:
    print(f"\n{col.replace('_', ' ').title()} Statistics by Health Status:")
    print(df.groupby('health_status')[col].describe())

"""# **PRODUCTIVITY/CONDITION FEATURES**"""

# Productivity and body condition
other_features = ['milk_production', 'body_condition_score']

plt.figure(figsize=(12, 5))
for i, col in enumerate(other_features):
    plt.subplot(1, 2, i + 1)
    sns.boxplot(data=df, x='health_status', y=col, hue='health_status', palette='pastel', legend=False)
    plt.title(f'{col.replace("_", " ").title()} vs Health Status')
    plt.xlabel('Health Status')
    plt.ylabel(col.replace("_", " ").title())

plt.tight_layout()
#plt.show()
"""# **Encode Labels and Preprocess**"""

import pandas as pd # Ensure pandas is imported
import numpy as np # Ensure numpy is imported
from sklearn.preprocessing import LabelEncoder, StandardScaler # Ensure these are imported
from sklearn.model_selection import train_test_split # Ensure this is imported
from sklearn.ensemble import RandomForestClassifier # Ensure this is imported
from sklearn.metrics import accuracy_score, classification_report # Ensure these are imported
import joblib # Ensure joblib is imported for saving/loading

# --- Assume 'df' DataFrame is already loaded and preprocessed (e.g., handling missing values)
# If 'df' is not defined here, make sure your actual script defines it correctly before this section.

# Encode categorical columns (e.g., 'breed_type', 'faecal_consistency', 'health_status')
le_breed = LabelEncoder()
df['breed_type_enc'] = le_breed.fit_transform(df['breed_type'])

le_faecal = LabelEncoder()
df['faecal_consistency_enc'] = le_faecal.fit_transform(df['faecal_consistency'])

le_health = LabelEncoder()
df['health_status_enc'] = le_health.fit_transform(df['health_status']) # healthy=0, unhealthy=1 (usually)

# Engineer features (if you do this before defining 'features' list)
# Example: If these are created earlier in your actual script, ensure they are part of 'df'
# before 'features' list is defined.
if 'activity_ratio' not in df.columns:
    df['activity_ratio'] = df['walking_capacity'] / (df['sleeping_duration'] + 1e-6)
if 'eating_efficiency' not in df.columns:
    df['eating_efficiency'] = df['milk_production'] / (df['eating_duration'] + 1e-6)
if 'vital_sign_index' not in df.columns:
    df['vital_sign_index'] = (df['heart_rate'] + df['respiratory_rate'] + df['body_temperature']) / 3


# Define features and target
features = ['body_temperature', 'breed_type_enc', 'milk_production', 'respiratory_rate',
            'walking_capacity', 'sleeping_duration', 'body_condition_score', 'heart_rate',
            'eating_duration', 'lying_down_duration', 'ruminating', 'rumen_fill',
            'faecal_consistency_enc', # Label encoded categorical feature
            'activity_ratio',      # Engineered feature
            'eating_efficiency',   # Engineered feature
            'vital_sign_index'     # Engineered feature
           ] # Make sure ALL your features, including engineered ones, are in this list

X = df[features]
y = df['health_status_enc']

# ********************************************************************************
# *** THIS IS THE CRUCIAL POINT TO GET THE EXACT FEATURE ORDER ***
# ********************************************************************************

print("\n--- COPY THIS LIST EXACTLY FOR training_features_for_model in app.py ---")
print(list(X.columns))
print("-----------------------------------------------------------------------\n")

# ********************************************************************************

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X) # X_scaled will now be a NumPy array

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train Random Forest Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train) # Model is fitted on a NumPy array, but the order was established by X.columns

# Predict on test set and evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=le_health.classes_))

# Save your model and scaler (make sure you do this in your training script)
joblib.dump(model, 'model.joblib')
joblib.dump(scaler, 'scaler.joblib')
joblib.dump(le_health, 'le_health.joblib')
joblib.dump(le_breed, 'le_breed.joblib') # Save your breed encoder!
joblib.dump(le_faecal, 'le_faecal.joblib') # Save your faecal consistency encoder!

print("\nModel, Scaler, and LabelEncoders saved successfully!")

"""# **Feature Importance Plot**"""

# Feature importance plot
feature_importance = pd.DataFrame({'feature': features, 'importance': model.feature_importances_})
feature_importance = feature_importance.sort_values(by='importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=feature_importance.head(10))
plt.title('Top 10 Most Important Features')
plt.tight_layout()
#plt.show()

"""## ** Engineered Features Visualization**"""

# Feature Engineering
#------------------------------
# Create new features
df['activity_ratio'] = df['walking_capacity'] / (df['sleeping_duration'] + df['lying_down_duration'])
df['eating_efficiency'] = df['eating_duration'] / df['ruminating']
df['vital_sign_index'] = (df['body_temperature'] - 38.5) + (df['respiratory_rate'] - 30)/10 + (df['heart_rate'] - 60)/10

# Encode categorical variables
le = LabelEncoder()
df['breed_type_encoded'] = le.fit_transform(df['breed_type'])
df['faecal_consistency_encoded'] = le.fit_transform(df['faecal_consistency'])
df['health_status_encoded'] = le.fit_transform(df['health_status'])

# Plot engineered features
engineered_features = ['activity_ratio', 'eating_efficiency', 'vital_sign_index']
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, col in enumerate(engineered_features):
    sns.boxplot(x='health_status', y=col, data=df, ax=axes[i])
    axes[i].set_title(f'{col.replace("_", " ").title()} vs Health Status')
plt.tight_layout()
#plt.show()

"""# **Define Function to Detect Specific Diseases & Generate Alerts**"""

import datetime # We'll need this for timestamps later, but defining it here for consistency

def get_rule_based_alerts(data):
    """
    Detects specific cattle diseases and generates structured alerts based on predefined rules.

    Args:
        data (dict): A dictionary containing raw physiological data points.
                     Example: {'body_temperature': 39.0, 'respiratory_rate': 30, ...}

    Returns:
        tuple: A tuple containing:
            - list: A list of strings, representing the names of specific diseases detected by rules.
            - list: A list of dictionaries, where each dictionary is a structured alert.
            - int: A count of individual abnormal indicators that triggered alerts (for simple confidence).
    """
    detected_diseases = []
    generated_alerts = []
    abnormal_indicator_count = 0

    # Centralized thresholds for readability and easy modification
    THRESHOLDS = {
        'body_temperature_high_respiratory': 39.5,
        'respiratory_rate_high_respiratory': 40,
        'faecal_consistency_abnormal': ['black faece', 'watery'],
        'milk_production_low': 8.0,
        'body_condition_score_low_reproductive': 2.5,
        'heart_rate_high_reproductive': 80,
        'walking_capacity_low': 9000,
        'body_temperature_high_systemic': 39.8,
        'heart_rate_high_systemic': 80,
        'respiratory_rate_high_systemic': 42,
    }

    # Respiratory Disease
    if data.get('body_temperature', 0) > THRESHOLDS['body_temperature_high_respiratory'] and \
       data.get('respiratory_rate', 0) > THRESHOLDS['respiratory_rate_high_respiratory']:
        detected_diseases.append('Respiratory Disease')
        generated_alerts.append({
            'symptom': 'body_temperature',
            'value': data.get('body_temperature'),
            'message': f"High body temperature detected ({data.get('body_temperature')}°C)!",
            'severity': 'Medium',
            'rule_triggered': 'Respiratory_Temp'
        })
        generated_alerts.append({
            'symptom': 'respiratory_rate',
            'value': data.get('respiratory_rate'),
            'message': f"High respiratory rate detected ({data.get('respiratory_rate')} breaths/min)!",
            'severity': 'Medium',
            'rule_triggered': 'Respiratory_Rate'
        })
        abnormal_indicator_count += 2

    # GI Disease
    faecal_consistency = data.get('faecal_consistency', '').lower()
    if faecal_consistency in THRESHOLDS['faecal_consistency_abnormal']:
        detected_diseases.append('Gastrointestinal Disease')
        generated_alerts.append({
            'symptom': 'faecal_consistency',
            'value': data.get('faecal_consistency'),
            'message': f"Abnormal faecal consistency detected ({data.get('faecal_consistency')})!",
            'severity': 'High',
            'rule_triggered': 'GI_Feces'
        })
        abnormal_indicator_count += 1

    # Udder Health Issue
    if data.get('milk_production', 0) < THRESHOLDS['milk_production_low']:
        detected_diseases.append('Udder Health Issue')
        generated_alerts.append({
            'symptom': 'milk_production',
            'value': data.get('milk_production'),
            'message': f"Very low milk production detected ({data.get('milk_production')} L/day)!",
            'severity': 'Medium',
            'rule_triggered': 'Udder_MilkProd'
        })
        abnormal_indicator_count += 1

    # Reproductive Disease
    if data.get('body_condition_score', 0) < THRESHOLDS['body_condition_score_low_reproductive'] and \
       data.get('heart_rate', 0) > THRESHOLDS['heart_rate_high_reproductive']:
        detected_diseases.append('Reproductive Disease')
        generated_alerts.append({
            'symptom': 'body_condition_score',
            'value': data.get('body_condition_score'),
            'message': f"Low body condition score detected ({data.get('body_condition_score')})!",
            'severity': 'Medium',
            'rule_triggered': 'Reproductive_BCS'
        })
        generated_alerts.append({
            'symptom': 'heart_rate',
            'value': data.get('heart_rate'),
            'message': f"High heart rate detected ({data.get('heart_rate')} bpm)!",
            'severity': 'Medium',
            'rule_triggered': 'Reproductive_HR'
        })
        abnormal_indicator_count += 2

    # Musculoskeletal Issue
    if data.get('walking_capacity', 0) < THRESHOLDS['walking_capacity_low']:
        detected_diseases.append('Lameness / Musculoskeletal Issue')
        generated_alerts.append({
            'symptom': 'walking_capacity',
            'value': data.get('walking_capacity'),
            'message': f"Low walking capacity detected ({data.get('walking_capacity')} steps/day)!",
            'severity': 'High',
            'rule_triggered': 'Musculoskeletal_Walking'
        })
        abnormal_indicator_count += 1

    # Systemic Infection
    if data.get('body_temperature', 0) > THRESHOLDS['body_temperature_high_systemic'] and \
       data.get('heart_rate', 0) > THRESHOLDS['heart_rate_high_systemic'] and \
       data.get('respiratory_rate', 0) > THRESHOLDS['respiratory_rate_high_systemic']:
        detected_diseases.append('Systemic Infection')
        generated_alerts.append({
            'symptom': 'body_temperature',
            'value': data.get('body_temperature'),
            'message': f"Critically high body temperature detected ({data.get('body_temperature')}°C)!",
            'severity': 'Critical',
            'rule_triggered': 'Systemic_Temp'
        })
        generated_alerts.append({
            'symptom': 'heart_rate',
            'value': data.get('heart_rate'),
            'message': f"Critically high heart rate detected ({data.get('heart_rate')} bpm)!",
            'severity': 'Critical',
            'rule_triggered': 'Systemic_HR'
        })
        generated_alerts.append({
            'symptom': 'respiratory_rate',
            'value': data.get('respiratory_rate'),
            'message': f"Critically high respiratory rate detected ({data.get('respiratory_rate')} breaths/min)!",
            'severity': 'Critical',
            'rule_triggered': 'Systemic_RR'
        })
        abnormal_indicator_count += 3

    # Remove duplicate alert messages based on 'message' key, but keep structured format
    unique_alerts_by_message = {}
    for alert in generated_alerts:
        unique_alerts_by_message[alert['message']] = alert
    final_alerts_list = list(unique_alerts_by_message.values())

    # Sort alerts by severity (Critical > High > Medium > Low) for dashboard display
    severity_order = {'Critical': 4, 'High': 3, 'Medium': 2, 'Low': 1}
    final_alerts_list.sort(key=lambda x: severity_order.get(x.get('severity', 'Low'), 0), reverse=True)

    return list(set(detected_diseases)), final_alerts_list, abnormal_indicator_count

# --- Example Usage of the refined function ---
sample_data = {
    'body_temperature': 40.1,
    'respiratory_rate': 45,
    'faecal_consistency': 'black faece',
    'milk_production': 10.0,
    'body_condition_score': 3.0,
    'heart_rate': 70,
    'walking_capacity': 8500
}

detected_diseases, alerts_list, indicator_count = get_rule_based_alerts(sample_data)

print("Detected Diseases (from rules):", detected_diseases)
print("\nStructured Alerts (from rules):")
for alert in alerts_list:
    print(alert)
print("\nAbnormal Indicator Count:", indicator_count)

"""# **Simulate Real-time Monitoring Output**"""

import datetime
# Assuming df, X_test, model, scaler, le_health, le_breed, le_faecal, and features are already defined
# and `get_rule_based_alerts` is defined as in our previous step.

# --- Start of the updated "Simulate Real-time Monitoring Output" section ---

# Pick a sample from the test set (using first sample here)
sample_idx = 0

# Retrieve the original data row (raw_data) and the feature row (for ML model)
# Ensure sample_raw is a dictionary to pass to get_rule_based_alerts
sample_raw_series = df.iloc[X_test.indices[sample_idx] if hasattr(X_test, 'indices') else sample_idx]
sample_raw_dict = sample_raw_series.to_dict() # Convert to dictionary for easier access in rule-based function

# Preprocess the raw sample data for the ML model
# This preprocessing function should be defined as we discussed, mirroring your training
# For demonstration, I'll put a placeholder for `preprocess_for_ml_prediction` if it's not directly in scope yet
# In your actual script, this would refer to the function you've already implemented/loaded
try:
    # Assuming 'features' list is available from your training script
    # and includes all columns, including engineered features and encoded categoricals needed by the model.
    # The preprocess_for_ml_prediction function would handle:
    # 1. Converting sample_raw_dict to a DataFrame.
    # 2. Applying label encoding using le_breed, le_faecal.
    # 3. Engineering features (activity_ratio, eating_efficiency, vital_sign_index).
    # 4. Selecting and ordering features as per 'features' list.
    # 5. Scaling using 'scaler'.
    # For now, we'll re-use sample_features which is already scaled if X_test was scaled.
    # In a real scenario, you'd call a dedicated preprocessing function here:
    # sample_features_processed = preprocess_for_ml_prediction(sample_raw_dict, le_breed, le_faecal, scaler, features)

    # For simulation, use the already prepared sample_features from X_test directly
    sample_features_for_ml = X_test[sample_idx].reshape(1, -1)

except Exception as e:
    print(f"Error during ML preprocessing simulation: {e}")
    # Handle error, perhaps skip ML prediction for this sample
    sample_features_for_ml = None # Or raise an error

# Predict probability and class using the ML model
pred_health_status = "Unknown"
confidence = 0.0
ml_prediction_probabilities = {}
overall_risk_level = "Low" # Default

if sample_features_for_ml is not None:
    pred_proba = model.predict_proba(sample_features_for_ml)[0]
    pred_class_idx = np.argmax(pred_proba)
    pred_health_status = le_health.inverse_transform([pred_class_idx])[0]
    confidence = pred_proba[pred_class_idx] * 100

    # Prepare ML prediction probabilities for output
    ml_prediction_probabilities = {
        le_health.inverse_transform([i])[0]: round(p * 100, 2)
        for i, p in enumerate(pred_proba)
    }

    # Initial Risk level logic based on ML prediction
    if pred_health_status.lower() == 'unhealthy':
        if confidence > 80:
            overall_risk_level = "High"
        elif confidence > 50:
            overall_risk_level = "Medium"
        else: # Unhealthy but lower confidence from ML
            overall_risk_level = "Low-Medium" # Or "Medium" as preferred
    else:
        overall_risk_level = "Low" # ML predicts healthy

# Detect diseases and alerts based on the raw sample using the *new* function
# This function requires the original raw data, not the preprocessed ML features
rule_based_diseases, structured_alerts_list, abnormal_indicator_count = get_rule_based_alerts(sample_raw_dict)


# --- Consolidate all information into a single structured output for dashboard ---

# Adjust overall health status and risk based on rule-based findings
if rule_based_diseases:
    # If rule-based system detects specific diseases, it indicates unhealthy status
    # and potentially elevates the risk, especially if ML was 'Healthy' or low confidence
    if overall_risk_level == "Low" or overall_risk_level == "Low-Medium":
        # If rules trigger high/critical severity alerts, elevate overall risk
        for alert in structured_alerts_list:
            if alert.get('severity') == 'Critical':
                overall_risk_level = "Critical"
                break # Found critical, no need to check further
            elif alert.get('severity') == 'High' and overall_risk_level != "Critical":
                overall_risk_level = "High"
            elif alert.get('severity') == 'Medium' and overall_risk_level not in ["Critical", "High"]:
                overall_risk_level = "Medium"

    # If any disease is detected by rules, overall health status is unhealthy
    pred_health_status = "Unhealthy"


# Final structured output dictionary
final_dashboard_output = {
    "cattle_id": f"Sample_Cattle_{sample_idx}", # Use a sample ID for simulation
    "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "monitoring_results": {
        "health_status": pred_health_status.capitalize(),
        "confidence": f"{confidence:.2f}%",
        "risk_level": overall_risk_level
    },
    "ml_predictions_detail": {
        "predicted_class": pred_health_status,
        "prediction_probabilities": ml_prediction_probabilities
    },
    "specific_diseases_detected": rule_based_diseases, # From rule-based function
    "alerts": structured_alerts_list, # Structured alerts from rule-based function
    "input_data_snapshot": sample_raw_dict # Original raw data for context on dashboard
}

# Print the final structured output (this would be returned by your Flask API)
import json
print("--- Consolidated Dashboard Output ---")
print(json.dumps(final_dashboard_output, indent=4))

# --- End of updated "Simulate Real-time Monitoring Output" section ---

"""# **Sample Unhealthy Cow Input (New Test Case)**"""

import datetime
import json
import pandas as pd # Make sure pandas is imported
import numpy as np # Make sure numpy is imported
import joblib # Make sure joblib is imported

# Assume le_breed, le_faecal, model, le_health, scaler are loaded or defined in your training environment.
# For this snippet to run independently and show the 'features' list,
# you'll need to have these objects defined or loaded beforehand.
# Example placeholders (replace with your actual loading or definitions):
try:
    # These would be loaded from your saved .joblib files in a real training script
    # For a minimal example, if they are not loaded, just define dummy ones to allow the code to run
    # and reveal the 'features' list.
    class DummyLabelEncoder:
        def __init__(self, classes):
            self.classes_ = classes
        def transform(self, values):
            return [self.classes_.index(v) if v in self.classes_ else 0 for v in values]

    le_breed = joblib.load('le_breed.joblib') # Load your actual encoder
    le_faecal = joblib.load('le_faecal.joblib') # Load your actual encoder
    le_health = joblib.load('le_health.joblib') # Load your actual encoder

    # Dummy model and scaler for the purpose of getting the 'features' list to print
    # You DO NOT need to load your actual model and scaler for this specific task of printing 'features'.
    # If your training script successfully ran before, these objects should exist.
    model = None # Placeholder, not needed for printing 'features'
    scaler = None # Placeholder, not needed for printing 'features'

    # Placeholder for get_rule_based_alerts if it's not defined elsewhere in your script
    def get_rule_based_alerts(data):
        return [], [], 0

except FileNotFoundError:
    print("Warning: Some .joblib files not found. Creating dummy encoders for 'features' list extraction.")
    le_breed = DummyLabelEncoder(['Normal Breed', 'Indigenous Breed', 'Cross Breed', 'Holstein'])
    le_faecal = DummyLabelEncoder(['ideal', 'dry', 'loose', 'watery', 'Black faece'])
    le_health = DummyLabelEncoder(['Healthy', 'Unhealthy']) # Add your actual health statuses


# --- Start of updated "Sample Unhealthy Cow Input (New Test Case)" section ---

# Define the data for a simulated unhealthy cow
unhealthy_data = {
    'body_temperature': 40.2,            # High → triggers respiratory + systemic
    'breed_type': 'Holstein',            # This will now be handled if not in le_breed.classes_
    'milk_production': 9.5,
    'respiratory_rate': 45,
    'walking_capacity': 8500,
    'sleeping_duration': 5.1,
    'body_condition_score': 2,
    'heart_rate': 75,
    'eating_duration': 2.7,
    'lying_down_duration': 11.0,
    'ruminating': 4.5,
    'rumen_fill': 2,
    'faecal_consistency': 'Black faece' # This will now be handled if not in le_faecal.classes_
}

# Create DataFrame from the input dictionary
test_df = pd.DataFrame([unhealthy_data])

# --- Robust Encoding for Categorical Features ---
breed_type_val = unhealthy_data.get('breed_type')
if breed_type_val in le_breed.classes_:
    test_df['breed_type_enc'] = le_breed.transform([breed_type_val])
else:
    fallback_breed_type = 'Normal Breed'
    if fallback_breed_type not in le_breed.classes_:
        fallback_breed_type = le_breed.classes_[0]
        print(f"Warning: Fallback 'Normal Breed' not found in le_breed.classes_. Using '{fallback_breed_type}' instead.")
    test_df['breed_type_enc'] = le_breed.transform([fallback_breed_type])
    print(f"Warning: Unseen breed_type '{breed_type_val}' in input. Encoding as '{fallback_breed_type}'.")

faecal_consistency_val = unhealthy_data.get('faecal_consistency')
if faecal_consistency_val in le_faecal.classes_:
    test_df['faecal_consistency_enc'] = le_faecal.transform([faecal_consistency_val])
else:
    fallback_faecal_consistency = 'ideal'
    if fallback_faecal_consistency not in le_faecal.classes_:
        fallback_faecal_consistency = le_faecal.classes_[0]
        print(f"Warning: Fallback 'ideal' not found in le_faecal.classes_. Using '{fallback_faecal_consistency}' instead.")
    test_df['faecal_consistency_enc'] = le_faecal.transform([fallback_faecal_consistency])
    print(f"Warning: Unseen faecal_consistency '{faecal_consistency_val}' in input. Encoding as '{fallback_faecal_consistency}'.")

# Engineer features as done during training (with epsilon for division by zero)
epsilon = 1e-6 # Define epsilon
test_df['activity_ratio'] = test_df['walking_capacity'] / (test_df['sleeping_duration'] + epsilon)
test_df['eating_efficiency'] = test_df['milk_production'] / (test_df['eating_duration'] + epsilon)
test_df['vital_sign_index'] = (test_df['heart_rate'] + test_df['respiratory_rate'] + test_df['body_temperature']) / 3

# Define the 'features' list - THIS IS THE CRITICAL LINE!
# You should have defined this list when you initially prepared your training data.
# This example is a very common structure. If your actual training script has a different list,
# or a different order, you must use that.
features = [
    'body_temperature',
    'milk_production',
    'respiratory_rate',
    'walking_capacity',
    'sleeping_duration',
    'body_condition_score',
    'heart_rate',
    'eating_duration',
    'lying_down_duration',
    'ruminating',
    'rumen_fill',
    'activity_ratio',      # Engineered feature
    'eating_efficiency',   # Engineered feature
    'vital_sign_index',    # Engineered feature
    'breed_type_Holstein', # Example: assuming this is one-hot encoded and present
    'breed_type_Normal Breed',
    'breed_type_Indigenous Breed',
    'breed_type_Cross Breed',
    'faecal_consistency_Black faece', # Example: assuming this is one-hot encoded and present
    'faecal_consistency_dry',
    'faecal_consistency_ideal',
    'faecal_consistency_loose',
    'faecal_consistency_watery'
    # Add ALL one-hot encoded columns in the exact order they appeared in X_train.columns
    # This often means alphabetical order if you used pd.get_dummies default settings.
]

# ***********************************************************************************
# *** ADDED: PRINT THE 'features' LIST TO GET THE EXACT ORDER AND NAMES ***
# ***********************************************************************************
print("\n--- COPY THIS LIST FOR training_features_for_model in app.py ---")
print(features)
print("-----------------------------------------------------------------\n")
# ***********************************************************************************

# Select features used for the model (must be the exact list used in training)
for feature in features:
    if feature not in test_df.columns:
        test_df[feature] = 0 # Assign a default if a feature column is unexpectedly missing
        # NOTE: Assigning 0 for a missing one-hot encoded column is correct.
        # For missing numerical engineered features, it might indicate an issue.

X_test_simulated = test_df[features] # This line effectively orders your DataFrame

# Scale features with the scaler fitted on training data
# NOTE: For this snippet to run, your 'scaler' object must be loaded or defined.
# If not, this line will cause an error unless you're just trying to get the 'features' list.
if scaler: # Only try to scale if scaler is defined/loaded
    X_test_simulated_scaled = scaler.transform(X_test_simulated)
else:
    print("Warning: Scaler not loaded/defined. Skipping scaling for this simulation.")
    X_test_simulated_scaled = X_test_simulated.values # Proceed with unscaled values for list printing

# Predict class and probabilities
# NOTE: For this snippet to run, your 'model' object must be loaded or defined.
if model: # Only try to predict if model is defined/loaded
    pred_proba = model.predict_proba(X_test_simulated_scaled)[0]
    pred_class_idx = np.argmax(pred_proba)
    pred_health_status = le_health.inverse_transform([pred_class_idx])[0]

    # Calculate confidence for the predicted class
    confidence = pred_proba[pred_class_idx] * 100

    # Prepare ML prediction probabilities for output
    ml_prediction_probabilities = {
        le_health.inverse_transform([i])[0]: round(p * 100, 2)
        for i, p in enumerate(pred_proba)
    }
else:
    print("Warning: Model not loaded/defined. Skipping ML prediction for this simulation.")
    pred_health_status = "N/A (Model Not Loaded)"
    confidence = 0.0
    ml_prediction_probabilities = {}

# --- Rule-Based Disease Detection and Alert Generation Part ---
rule_based_diseases, structured_alerts_list, abnormal_indicator_count = get_rule_based_alerts(unhealthy_data)

# --- Consolidate and Finalize Output for Dashboard ---

overall_health_status = pred_health_status.capitalize()
overall_risk_level = "Low" # Default based on ML prediction

if pred_health_status.lower() == 'unhealthy':
    if confidence > 80:
        overall_risk_level = "High"
    elif confidence > 50:
        overall_risk_level = "Medium"
    else:
        overall_risk_level = "Low-Medium"
else:
    overall_risk_level = "Low"

if rule_based_diseases:
    if overall_risk_level == "Low" or overall_risk_level == "Low-Medium":
        for alert in structured_alerts_list:
            if alert.get('severity') == 'Critical':
                overall_risk_level = "Critical"
                break
            elif alert.get('severity') == 'High' and overall_risk_level != "Critical":
                overall_risk_level = "High"
            elif alert.get('severity') == 'Medium' and overall_risk_level not in ["Critical", "High"]:
                overall_risk_level = "Medium"

    overall_health_status = "Unhealthy"

# Final structured output dictionary
final_dashboard_output = {
    "cattle_id": "Unhealthy_Cattle_Test_001",
    "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "monitoring_results": {
        "health_status": overall_health_status,
        "confidence": f"{confidence:.2f}%",
        "risk_level": overall_risk_level
    },
    "ml_predictions_detail": {
        "predicted_class": pred_health_status,
        "prediction_probabilities": ml_prediction_probabilities
    },
    "specific_diseases_detected": rule_based_diseases,
    "alerts": structured_alerts_list,
    "input_data_snapshot": unhealthy_data
}

# Print the final structured output
print("--- Consolidated Dashboard Output for Unhealthy Cow Test ---")
print(json.dumps(final_dashboard_output, indent=4))

# --- End of updated "Sample Unhealthy Cow Input (New Test Case)" section ---