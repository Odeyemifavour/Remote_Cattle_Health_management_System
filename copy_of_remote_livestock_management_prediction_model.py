# -*- coding: utf-8 -*-
"""Copy of Remote_Livestock_Management_Prediction_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rDA39qMhu49uV1CBpiyFs5qkgNe5c7-4

## **IMPORT LIBARIES**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib



"""# **LOAD AND PREVIEW DATASET**"""

df = pd.read_excel('cattle_dataset.xlsx')
print("Dataset Shape:", df.shape)
print("\nFirst few rows:")
print(df.head())
print("\nData Info:")
df.info()

"""# **Distribution of health status**"""

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='health_status', hue='health_status', palette={'healthy': 'green', 'unhealthy': 'red'}, legend=False)
plt.title('Distribution of Health Status')
plt.xlabel('Health Status')
plt.ylabel('Count')
plt.xticks(rotation=45)
# plt.show()

"""# **breed type distribution based on health status**"""

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='breed_type', hue='health_status', palette={'healthy': 'green', 'unhealthy': 'red'})
plt.title('Health Status by Breed Type')
plt.xlabel('Breed Type')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Health Status')
plt.tight_layout()
# plt.show()

"""# **Numerical features summary**"""

# Basic statistics for numerical columns
print("\nNumerical Features Statistics:")
print(df.describe())

numerical_cols = ['body_temperature', 'respiratory_rate', 'heart_rate', 'milk_production',
                  'sleeping_duration', 'eating_duration', 'walking_capacity',
                  'lying_down_duration', 'body_condition_score', 'rumen_fill', 'ruminating']

plt.figure(figsize=(18, 30))
for i, col in enumerate(numerical_cols):
    plt.subplot(len(numerical_cols) // 2 + 1, 2, i + 1)
    sns.boxplot(data=df, x='health_status', y=col)
    plt.title(f'{col.replace("_", " ").title()} vs Health Status')
    plt.xticks(rotation=30)

plt.tight_layout()
# plt.show()

df[numerical_cols].hist(figsize=(18, 12), bins=30, edgecolor='black')
plt.tight_layout()
# plt.show()
"""# **Categorical Features Summary**"""

# Summary for categorical features
print("\nCategorical Features Distribution:")

categorical_cols = ['breed_type', 'faecal_consistency', 'health_status']

for col in categorical_cols:
    print(f"\n{col} value counts:")
    print(df[col].value_counts())

categorical_cols = ['breed_type', 'faecal_consistency', 'health_status']

plt.figure(figsize=(18, 5))

for i, col in enumerate(categorical_cols):
    plt.subplot(1, 3, i + 1)
    sns.countplot(data=df, x=col, hue=col, legend=False)
    plt.title(f'{col.replace("_", " ").title()} Distribution')
    plt.xlabel(col.replace("_", " ").title())
    plt.ylabel('Count')
    plt.xticks(rotation=30)

plt.tight_layout()
# plt.show()

"""# Vital Sign Summary"""

# Vital sign features
vital_signs = ['body_temperature', 'respiratory_rate', 'heart_rate']

# Plot boxplots by health status with proper palette handling
plt.figure(figsize=(15, 5))

for i, col in enumerate(vital_signs, 1):
    plt.subplot(1, 3, i)
    sns.boxplot(data=df, x='health_status', y=col, hue='health_status', palette='coolwarm', legend=False)
    plt.title(f'{col.replace("_", " ").title()} by Health Status')
    plt.xlabel('Health Status')
    plt.ylabel(col.replace("_", " ").title())

plt.tight_layout()
# plt.show()

"""# Behavioural Analysis summary"""

# Behavioral features
behavioral_features = ['walking_capacity', 'sleeping_duration', 'eating_duration',
                       'lying_down_duration', 'ruminating', 'rumen_fill']

plt.figure(figsize=(18, 15))
for i, col in enumerate(behavioral_features):
    plt.subplot(3, 2, i + 1)
    sns.boxplot(data=df, x='health_status', y=col, hue='health_status', palette='Set2', legend=False)
    plt.title(f'{col.replace("_", " ").title()} vs Health Status')
    plt.xlabel('Health Status')
    plt.ylabel(col.replace("_", " ").title())

plt.tight_layout()
# plt.show()

# Define behavioral features
behavioral = ['walking_capacity', 'sleeping_duration', 'eating_duration',
              'lying_down_duration', 'ruminating', 'rumen_fill']

# Behavioral statistics grouped by health status
print("\nBehavioral Patterns Statistics:")
for col in behavioral:
    print(f"\n{col.replace('_', ' ').title()} Statistics by Health Status:")
    print(df.groupby('health_status')[col].describe())

"""# **PRODUCTIVITY/CONDITION FEATURES**"""

# Productivity and body condition
other_features = ['milk_production', 'body_condition_score']

plt.figure(figsize=(12, 5))
for i, col in enumerate(other_features):
    plt.subplot(1, 2, i + 1)
    sns.boxplot(data=df, x='health_status', y=col, hue='health_status', palette='pastel', legend=False)
    plt.title(f'{col.replace("_", " ").title()} vs Health Status')
    plt.xlabel('Health Status')
    plt.ylabel(col.replace("_", " ").title())

plt.tight_layout()
# plt.show()

"""# **Encode Labels and Preprocess**"""

# Encode categorical columns (e.g., 'breed_type', 'faecal_consistency', 'health_status')
le_breed = LabelEncoder()
df['breed_type_enc'] = le_breed.fit_transform(df['breed_type'])

le_faecal = LabelEncoder()
df['faecal_consistency_enc'] = le_faecal.fit_transform(df['faecal_consistency'])

le_health = LabelEncoder()
df['health_status_enc'] = le_health.fit_transform(df['health_status'])  # healthy=0, unhealthy=1 (usually)

# Define features and target
features = ['body_temperature', 'breed_type_enc', 'milk_production', 'respiratory_rate',
            'walking_capacity', 'sleeping_duration', 'body_condition_score', 'heart_rate',
            'eating_duration', 'lying_down_duration', 'ruminating', 'rumen_fill', 'faecal_consistency_enc']

X = df[features]
y = df['health_status_enc']

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""# **Split Data and Train Model**"""

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train Random Forest Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Predict on test set and evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=le_health.classes_))

# flask-api/app.py

# ... (your existing model training and evaluation code) ...

# Add these lines to save the trained model and preprocessing tools:
# We will save them directly into your 'flask-api' folder.
model_path = 'flask-api/model.joblib'
scaler_path = 'flask-api/scaler.joblib'
le_health_path = 'flask-api/le_health.joblib' # For health status LabelEncoder

# Save the trained model (e.g., RandomForestClassifier)
joblib.dump(model, model_path)
print(f"Model saved to {model_path}")

# Save the StandardScaler (used for scaling numerical features)
joblib.dump(scaler, scaler_path)
print(f"Scaler saved to {scaler_path}")

# Save the LabelEncoder for 'health_status'
joblib.dump(le_health, le_health_path)
print(f"Label Encoder for health_status saved to {le_health_path}")

# ... (any remaining print statements or code you had at the very end of your script) ...
"""# **Feature Importance Plot**"""

# Feature importance plot
feature_importance = pd.DataFrame({'feature': features, 'importance': model.feature_importances_})
feature_importance = feature_importance.sort_values(by='importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='importance', y='feature', data=feature_importance.head(10))
plt.title('Top 10 Most Important Features')
plt.tight_layout()
# plt.show()

"""## ** Engineered Features Visualization**"""

# Feature Engineering
#------------------------------
# Create new features
df['activity_ratio'] = df['walking_capacity'] / (df['sleeping_duration'] + df['lying_down_duration'])
df['eating_efficiency'] = df['eating_duration'] / df['ruminating']
df['vital_sign_index'] = (df['body_temperature'] - 38.5) + (df['respiratory_rate'] - 30)/10 + (df['heart_rate'] - 60)/10

# Encode categorical variables
le = LabelEncoder()
df['breed_type_encoded'] = le.fit_transform(df['breed_type'])
df['faecal_consistency_encoded'] = le.fit_transform(df['faecal_consistency'])
df['health_status_encoded'] = le.fit_transform(df['health_status'])

# Plot engineered features
engineered_features = ['activity_ratio', 'eating_efficiency', 'vital_sign_index']
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, col in enumerate(engineered_features):
    sns.boxplot(x='health_status', y=col, data=df, ax=axes[i])
    axes[i].set_title(f'{col.replace("_", " ").title()} vs Health Status')
plt.tight_layout()
# plt.show()

"""# **Define Function to Detect Specific Diseases & Generate Alerts**"""

import datetime # We'll need this for timestamps later, but defining it here for consistency

def get_rule_based_alerts(data):
    """
    Detects specific cattle diseases and generates structured alerts based on predefined rules.

    Args:
        data (dict): A dictionary containing raw physiological data points.
                     Example: {'body_temperature': 39.0, 'respiratory_rate': 30, ...}

    Returns:
        tuple: A tuple containing:
            - list: A list of strings, representing the names of specific diseases detected by rules.
            - list: A list of dictionaries, where each dictionary is a structured alert.
            - int: A count of individual abnormal indicators that triggered alerts (for simple confidence).
    """
    detected_diseases = []
    generated_alerts = []
    abnormal_indicator_count = 0

    # Centralized thresholds for readability and easy modification
    THRESHOLDS = {
        'body_temperature_high_respiratory': 39.5,
        'respiratory_rate_high_respiratory': 40,
        'faecal_consistency_abnormal': ['black faece', 'watery'],
        'milk_production_low': 8.0,
        'body_condition_score_low_reproductive': 2.5,
        'heart_rate_high_reproductive': 80,
        'walking_capacity_low': 9000,
        'body_temperature_high_systemic': 39.8,
        'heart_rate_high_systemic': 80,
        'respiratory_rate_high_systemic': 42,
    }

    # Respiratory Disease
    if data.get('body_temperature', 0) > THRESHOLDS['body_temperature_high_respiratory'] and \
       data.get('respiratory_rate', 0) > THRESHOLDS['respiratory_rate_high_respiratory']:
        detected_diseases.append('Respiratory Disease')
        generated_alerts.append({
            'symptom': 'body_temperature',
            'value': data.get('body_temperature'),
            'message': f"High body temperature detected ({data.get('body_temperature')}°C)!",
            'severity': 'Medium',
            'rule_triggered': 'Respiratory_Temp'
        })
        generated_alerts.append({
            'symptom': 'respiratory_rate',
            'value': data.get('respiratory_rate'),
            'message': f"High respiratory rate detected ({data.get('respiratory_rate')} breaths/min)!",
            'severity': 'Medium',
            'rule_triggered': 'Respiratory_Rate'
        })
        abnormal_indicator_count += 2

    # GI Disease
    faecal_consistency = data.get('faecal_consistency', '').lower()
    if faecal_consistency in THRESHOLDS['faecal_consistency_abnormal']:
        detected_diseases.append('Gastrointestinal Disease')
        generated_alerts.append({
            'symptom': 'faecal_consistency',
            'value': data.get('faecal_consistency'),
            'message': f"Abnormal faecal consistency detected ({data.get('faecal_consistency')})!",
            'severity': 'High',
            'rule_triggered': 'GI_Feces'
        })
        abnormal_indicator_count += 1

    # Udder Health Issue
    if data.get('milk_production', 0) < THRESHOLDS['milk_production_low']:
        detected_diseases.append('Udder Health Issue')
        generated_alerts.append({
            'symptom': 'milk_production',
            'value': data.get('milk_production'),
            'message': f"Very low milk production detected ({data.get('milk_production')} L/day)!",
            'severity': 'Medium',
            'rule_triggered': 'Udder_MilkProd'
        })
        abnormal_indicator_count += 1

    # Reproductive Disease
    if data.get('body_condition_score', 0) < THRESHOLDS['body_condition_score_low_reproductive'] and \
       data.get('heart_rate', 0) > THRESHOLDS['heart_rate_high_reproductive']:
        detected_diseases.append('Reproductive Disease')
        generated_alerts.append({
            'symptom': 'body_condition_score',
            'value': data.get('body_condition_score'),
            'message': f"Low body condition score detected ({data.get('body_condition_score')})!",
            'severity': 'Medium',
            'rule_triggered': 'Reproductive_BCS'
        })
        generated_alerts.append({
            'symptom': 'heart_rate',
            'value': data.get('heart_rate'),
            'message': f"High heart rate detected ({data.get('heart_rate')} bpm)!",
            'severity': 'Medium',
            'rule_triggered': 'Reproductive_HR'
        })
        abnormal_indicator_count += 2

    # Musculoskeletal Issue
    if data.get('walking_capacity', 0) < THRESHOLDS['walking_capacity_low']:
        detected_diseases.append('Lameness / Musculoskeletal Issue')
        generated_alerts.append({
            'symptom': 'walking_capacity',
            'value': data.get('walking_capacity'),
            'message': f"Low walking capacity detected ({data.get('walking_capacity')} steps/day)!",
            'severity': 'High',
            'rule_triggered': 'Musculoskeletal_Walking'
        })
        abnormal_indicator_count += 1

    # Systemic Infection
    if data.get('body_temperature', 0) > THRESHOLDS['body_temperature_high_systemic'] and \
       data.get('heart_rate', 0) > THRESHOLDS['heart_rate_high_systemic'] and \
       data.get('respiratory_rate', 0) > THRESHOLDS['respiratory_rate_high_systemic']:
        detected_diseases.append('Systemic Infection')
        generated_alerts.append({
            'symptom': 'body_temperature',
            'value': data.get('body_temperature'),
            'message': f"Critically high body temperature detected ({data.get('body_temperature')}°C)!",
            'severity': 'Critical',
            'rule_triggered': 'Systemic_Temp'
        })
        generated_alerts.append({
            'symptom': 'heart_rate',
            'value': data.get('heart_rate'),
            'message': f"Critically high heart rate detected ({data.get('heart_rate')} bpm)!",
            'severity': 'Critical',
            'rule_triggered': 'Systemic_HR'
        })
        generated_alerts.append({
            'symptom': 'respiratory_rate',
            'value': data.get('respiratory_rate'),
            'message': f"Critically high respiratory rate detected ({data.get('respiratory_rate')} breaths/min)!",
            'severity': 'Critical',
            'rule_triggered': 'Systemic_RR'
        })
        abnormal_indicator_count += 3

    # Remove duplicate alert messages based on 'message' key, but keep structured format
    unique_alerts_by_message = {}
    for alert in generated_alerts:
        unique_alerts_by_message[alert['message']] = alert
    final_alerts_list = list(unique_alerts_by_message.values())

    # Sort alerts by severity (Critical > High > Medium > Low) for dashboard display
    severity_order = {'Critical': 4, 'High': 3, 'Medium': 2, 'Low': 1}
    final_alerts_list.sort(key=lambda x: severity_order.get(x.get('severity', 'Low'), 0), reverse=True)

    return list(set(detected_diseases)), final_alerts_list, abnormal_indicator_count

# --- Example Usage of the refined function ---
sample_data = {
    'body_temperature': 40.1,
    'respiratory_rate': 45,
    'faecal_consistency': 'black faece',
    'milk_production': 10.0,
    'body_condition_score': 3.0,
    'heart_rate': 70,
    'walking_capacity': 8500
}

detected_diseases, alerts_list, indicator_count = get_rule_based_alerts(sample_data)

print("Detected Diseases (from rules):", detected_diseases)
print("\nStructured Alerts (from rules):")
for alert in alerts_list:
    print(alert)
print("\nAbnormal Indicator Count:", indicator_count)

"""# **Simulate Real-time Monitoring Output**"""

import datetime
# Assuming df, X_test, model, scaler, le_health, le_breed, le_faecal, and features are already defined
# and `get_rule_based_alerts` is defined as in our previous step.

# --- Start of the updated "Simulate Real-time Monitoring Output" section ---

# Pick a sample from the test set (using first sample here)
sample_idx = 0

# Retrieve the original data row (raw_data) and the feature row (for ML model)
# Ensure sample_raw is a dictionary to pass to get_rule_based_alerts
sample_raw_series = df.iloc[X_test.indices[sample_idx] if hasattr(X_test, 'indices') else sample_idx]
sample_raw_dict = sample_raw_series.to_dict() # Convert to dictionary for easier access in rule-based function

# Preprocess the raw sample data for the ML model
# This preprocessing function should be defined as we discussed, mirroring your training
# For demonstration, I'll put a placeholder for `preprocess_for_ml_prediction` if it's not directly in scope yet
# In your actual script, this would refer to the function you've already implemented/loaded
try:
    # Assuming 'features' list is available from your training script
    # and includes all columns, including engineered features and encoded categoricals needed by the model.
    # The preprocess_for_ml_prediction function would handle:
    # 1. Converting sample_raw_dict to a DataFrame.
    # 2. Applying label encoding using le_breed, le_faecal.
    # 3. Engineering features (activity_ratio, eating_efficiency, vital_sign_index).
    # 4. Selecting and ordering features as per 'features' list.
    # 5. Scaling using 'scaler'.
    # For now, we'll re-use sample_features which is already scaled if X_test was scaled.
    # In a real scenario, you'd call a dedicated preprocessing function here:
    # sample_features_processed = preprocess_for_ml_prediction(sample_raw_dict, le_breed, le_faecal, scaler, features)

    # For simulation, use the already prepared sample_features from X_test directly
    sample_features_for_ml = X_test[sample_idx].reshape(1, -1)

except Exception as e:
    print(f"Error during ML preprocessing simulation: {e}")
    # Handle error, perhaps skip ML prediction for this sample
    sample_features_for_ml = None # Or raise an error

# Predict probability and class using the ML model
pred_health_status = "Unknown"
confidence = 0.0
ml_prediction_probabilities = {}
overall_risk_level = "Low" # Default

if sample_features_for_ml is not None:
    pred_proba = model.predict_proba(sample_features_for_ml)[0]
    pred_class_idx = np.argmax(pred_proba)
    pred_health_status = le_health.inverse_transform([pred_class_idx])[0]
    confidence = pred_proba[pred_class_idx] * 100

    # Prepare ML prediction probabilities for output
    ml_prediction_probabilities = {
        le_health.inverse_transform([i])[0]: round(p * 100, 2)
        for i, p in enumerate(pred_proba)
    }

    # Initial Risk level logic based on ML prediction
    if pred_health_status.lower() == 'unhealthy':
        if confidence > 80:
            overall_risk_level = "High"
        elif confidence > 50:
            overall_risk_level = "Medium"
        else: # Unhealthy but lower confidence from ML
            overall_risk_level = "Low-Medium" # Or "Medium" as preferred
    else:
        overall_risk_level = "Low" # ML predicts healthy

# Detect diseases and alerts based on the raw sample using the *new* function
# This function requires the original raw data, not the preprocessed ML features
rule_based_diseases, structured_alerts_list, abnormal_indicator_count = get_rule_based_alerts(sample_raw_dict)


# --- Consolidate all information into a single structured output for dashboard ---

# Adjust overall health status and risk based on rule-based findings
if rule_based_diseases:
    # If rule-based system detects specific diseases, it indicates unhealthy status
    # and potentially elevates the risk, especially if ML was 'Healthy' or low confidence
    if overall_risk_level == "Low" or overall_risk_level == "Low-Medium":
        # If rules trigger high/critical severity alerts, elevate overall risk
        for alert in structured_alerts_list:
            if alert.get('severity') == 'Critical':
                overall_risk_level = "Critical"
                break # Found critical, no need to check further
            elif alert.get('severity') == 'High' and overall_risk_level != "Critical":
                overall_risk_level = "High"
            elif alert.get('severity') == 'Medium' and overall_risk_level not in ["Critical", "High"]:
                overall_risk_level = "Medium"

    # If any disease is detected by rules, overall health status is unhealthy
    pred_health_status = "Unhealthy"


# Final structured output dictionary
final_dashboard_output = {
    "cattle_id": f"Sample_Cattle_{sample_idx}", # Use a sample ID for simulation
    "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "monitoring_results": {
        "health_status": pred_health_status.capitalize(),
        "confidence": f"{confidence:.2f}%",
        "risk_level": overall_risk_level
    },
    "ml_predictions_detail": {
        "predicted_class": pred_health_status,
        "prediction_probabilities": ml_prediction_probabilities
    },
    "specific_diseases_detected": rule_based_diseases, # From rule-based function
    "alerts": structured_alerts_list, # Structured alerts from rule-based function
    "input_data_snapshot": sample_raw_dict # Original raw data for context on dashboard
}

# Print the final structured output (this would be returned by your Flask API)
import json
print("--- Consolidated Dashboard Output ---")
print(json.dumps(final_dashboard_output, indent=4))

# --- End of updated "Simulate Real-time Monitoring Output" section ---

"""# **Sample Unhealthy Cow Input (New Test Case)**"""

import datetime
import json

# Assume le_breed, le_faecal, model, le_health, scaler, features (list of ML model features)
# and get_rule_based_alerts function are already defined and loaded/in scope.

# --- Start of updated "Sample Unhealthy Cow Input (New Test Case)" section ---

# Define the data for a simulated unhealthy cow
unhealthy_data = {
    'body_temperature': 40.2,            # High → triggers respiratory + systemic
    'breed_type': 'Holstein',            # This will now be handled if not in le_breed.classes_
    'milk_production': 9.5,
    'respiratory_rate': 45,
    'walking_capacity': 8500,
    'sleeping_duration': 5.1,
    'body_condition_score': 2,
    'heart_rate': 75,
    'eating_duration': 2.7,
    'lying_down_duration': 11.0,
    'ruminating': 4.5,
    'rumen_fill': 2,
    'faecal_consistency': 'Black faece' # This will now be handled if not in le_faecal.classes_
}

# Create DataFrame from the input dictionary
test_df = pd.DataFrame([unhealthy_data])

# --- Robust Encoding for Categorical Features ---
# Ensure these values are in le_breed.classes_ and le_faecal.classes_
# A better practice is to define a consistent 'unknown' or 'other' category during training
# or use the mode of the training data. For now, we'll try a known common category.

# For 'breed_type'
breed_type_val = unhealthy_data.get('breed_type')
if breed_type_val in le_breed.classes_:
    test_df['breed_type_enc'] = le_breed.transform([breed_type_val])
else:
    # Fallback: Use a known category from training data (e.g., 'Normal Breed' or the mode)
    # IMPORTANT: 'Normal Breed' MUST exist in your le_breed.classes_
    fallback_breed_type = 'Normal Breed' # Adjust this to a category known by your le_breed
    if fallback_breed_type not in le_breed.classes_:
        # If even fallback_breed_type isn't found, pick the first class known by the encoder
        fallback_breed_type = le_breed.classes_[0]
        print(f"Warning: Fallback 'Normal Breed' not found in le_breed.classes_. Using '{fallback_breed_type}' instead.")

    test_df['breed_type_enc'] = le_breed.transform([fallback_breed_type])
    print(f"Warning: Unseen breed_type '{breed_type_val}' in input. Encoding as '{fallback_breed_type}'.")


# For 'faecal_consistency'
faecal_consistency_val = unhealthy_data.get('faecal_consistency')
if faecal_consistency_val in le_faecal.classes_:
    test_df['faecal_consistency_enc'] = le_faecal.transform([faecal_consistency_val])
else:
    # Fallback: Use a known category from training data (e.g., 'ideal' or the mode)
    # IMPORTANT: 'ideal' MUST exist in your le_faecal.classes_
    fallback_faecal_consistency = 'ideal' # Adjust this to a category known by your le_faecal
    if fallback_faecal_consistency not in le_faecal.classes_:
        fallback_faecal_consistency = le_faecal.classes_[0]
        print(f"Warning: Fallback 'ideal' not found in le_faecal.classes_. Using '{fallback_faecal_consistency}' instead.")

    test_df['faecal_consistency_enc'] = le_faecal.transform([fallback_faecal_consistency])
    print(f"Warning: Unseen faecal_consistency '{faecal_consistency_val}' in input. Encoding as '{fallback_faecal_consistency}'.")


# Engineer features as done during training (with epsilon for division by zero)
test_df['activity_ratio'] = test_df['walking_capacity'] / (test_df['sleeping_duration'] + 1e-6)
test_df['eating_efficiency'] = test_df['milk_production'] / (test_df['eating_duration'] + 1e-6)
test_df['vital_sign_index'] = (test_df['heart_rate'] + test_df['respiratory_rate'] + test_df['body_temperature']) / 3

# Select features used for the model (must be the exact list used in training)
for feature in features:
    if feature not in test_df.columns:
        test_df[feature] = 0 # Assign a default if a feature column is unexpectedly missing

X_test_simulated = test_df[features]

# Scale features with the scaler fitted on training data
X_test_simulated_scaled = scaler.transform(X_test_simulated)

# Predict class and probabilities
pred_proba = model.predict_proba(X_test_simulated_scaled)[0]
pred_class_idx = np.argmax(pred_proba)
pred_health_status = le_health.inverse_transform([pred_class_idx])[0]

# Calculate confidence for the predicted class
confidence = pred_proba[pred_class_idx] * 100

# Prepare ML prediction probabilities for output
ml_prediction_probabilities = {
    le_health.inverse_transform([i])[0]: round(p * 100, 2)
    for i, p in enumerate(pred_proba)
}

# --- Rule-Based Disease Detection and Alert Generation Part ---
# Use the new structured function on original raw data dictionary
rule_based_diseases, structured_alerts_list, abnormal_indicator_count = get_rule_based_alerts(unhealthy_data)

# --- Consolidate and Finalize Output for Dashboard ---

overall_health_status = pred_health_status.capitalize()
overall_risk_level = "Low" # Default based on ML prediction

# Initial Risk level logic based on ML prediction
if pred_health_status.lower() == 'unhealthy':
    if confidence > 80:
        overall_risk_level = "High"
    elif confidence > 50:
        overall_risk_level = "Medium"
    else:
        overall_risk_level = "Low-Medium"
else:
    overall_risk_level = "Low"


# Adjust overall health status and risk based on rule-based findings
if rule_based_diseases:
    if overall_risk_level == "Low" or overall_risk_level == "Low-Medium":
        for alert in structured_alerts_list:
            if alert.get('severity') == 'Critical':
                overall_risk_level = "Critical"
                break
            elif alert.get('severity') == 'High' and overall_risk_level != "Critical":
                overall_risk_level = "High"
            elif alert.get('severity') == 'Medium' and overall_risk_level not in ["Critical", "High"]:
                overall_risk_level = "Medium"

    overall_health_status = "Unhealthy"

# Final structured output dictionary
final_dashboard_output = {
    "cattle_id": "Unhealthy_Cattle_Test_001",
    "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "monitoring_results": {
        "health_status": overall_health_status,
        "confidence": f"{confidence:.2f}%",
        "risk_level": overall_risk_level
    },
    "ml_predictions_detail": {
        "predicted_class": pred_health_status,
        "prediction_probabilities": ml_prediction_probabilities
    },
    "specific_diseases_detected": rule_based_diseases,
    "alerts": structured_alerts_list,
    "input_data_snapshot": unhealthy_data
}

# Print the final structured output
print("--- Consolidated Dashboard Output for Unhealthy Cow Test ---")
print(json.dumps(final_dashboard_output, indent=4))

# --- End of updated "Sample Unhealthy Cow Input (New Test Case)" section ---